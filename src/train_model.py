import os
import json
from datasets import Dataset
from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments
from sklearn.metrics import accuracy_score, f1_score, classification_report
import torch
import numpy as np
from tqdm import tqdm

# ê²½ë¡œ ì„¤ì •
BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
DATA_DIR = os.path.join(BASE_DIR, "data", "processed")
OUTPUT_DIR = os.path.join(BASE_DIR, "outputs")
os.makedirs(OUTPUT_DIR, exist_ok=True)

# ë°ì´í„° ë¡œë“œ
def load_dataset(filename):
    path = os.path.join(DATA_DIR, filename)
    with open(path, "r", encoding="utf-8") as f:
        data = json.load(f)
    return Dataset.from_list(data)

tokenized_train = load_dataset("tokenized_train.json")
tokenized_val = load_dataset("tokenized_val.json")
tokenized_test = load_dataset("tokenized_test.json")

# tokenizer & model ë¡œë“œ
tokenizer = BertTokenizer.from_pretrained("bert-base-multilingual-cased")
labels = set(tokenized_train["label"])
model = BertForSequenceClassification.from_pretrained(
    "bert-base-multilingual-cased",
    num_labels=max(labels) + 1 
)

# í‰ê°€ ì§€í‘œ ì •ì˜
def compute_metrics(p):
    preds = np.argmax(p.predictions, axis=1)
    labels = p.label_ids
    return {
        "accuracy": accuracy_score(labels, preds),
        "f1_macro": f1_score(labels, preds, average="macro")
    }

# í•™ìŠµ ì„¤ì • (êµ¬ë²„ì „ í˜¸í™˜)
training_args = TrainingArguments(
    output_dir=OUTPUT_DIR,
    num_train_epochs=3,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    logging_dir=os.path.join(OUTPUT_DIR, "logs"),
    do_train=True,
    do_eval=True
)

# Trainer êµ¬ì„±
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_train,
    eval_dataset=tokenized_val,
    tokenizer=tokenizer
)

# í•™ìŠµ ì‹œì‘
trainer.train()

# ìˆ˜ë™ í‰ê°€ ì‹¤í–‰
print("\nğŸ“Š í…ŒìŠ¤íŠ¸ì…‹ ì„±ëŠ¥:")
eval_result = trainer.evaluate(tokenized_test)
print(eval_result)

# ìƒì„¸ ë¦¬í¬íŠ¸
preds = trainer.predict(tokenized_test)
preds_labels = np.argmax(preds.predictions, axis=1)
true_labels = preds.label_ids
print("\nğŸ“‹ ë¶„ë¥˜ ë¦¬í¬íŠ¸:")
print(classification_report(true_labels, preds_labels))

# tqdm í™œìš©í•´ ì˜ˆì¸¡ ê²°ê³¼ ìš”ì•½ ì¶œë ¥
print("\nğŸ” ì˜ˆì¸¡ ìƒ˜í”Œ:")
for i in tqdm(range(min(10, len(preds_labels)))):
    print(f"[{i+1}] ì˜ˆì¸¡: {preds_labels[i]} / ì‹¤ì œ: {true_labels[i]}")

# ëª¨ë¸ ì €ì¥
model.save_pretrained(os.path.join(OUTPUT_DIR, "bert_case_classifier"))
tokenizer.save_pretrained(os.path.join(OUTPUT_DIR, "bert_case_classifier"))
print("\nâœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: outputs/bert_case_classifier")
